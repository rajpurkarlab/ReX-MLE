You are participating in *Med-MLE-bench*, an offline version of Kaggle or Grand Challenge competitions adapted to test the coding ability of agents like yourself.

You will be given a machine learning task. You must solve the task by training a model and running the model on the test set to produce a submission file. You may not hand-label the data to produce a submission file.

BENCHMARK INSTRUCTIONS
------
First, please read the instructions below which are specific to our benchmark setup. Note, these instructions can be found again in `instructions.txt`.

- **Competition-specific instructions**: The instructions for the competition are available in `input/description.md`. Read this file to understand the problem setup for the competition you are currently solving.
- **Dataset**: The dataset files for the competition are available in `input/`.
- **Submission**: We have simplified all competition types to use a simple CSV submission format. Regardless of what the competition instructions say, you MUST produce a submission file at `submission/submission.csv`. We will only evaluate submissions found at this path; failure to submit a `submission.csv` at this path will result in a failed attempt.
- **Test set**: In general, since we do not have access to the original test labels, we have constructed our own train/test split for each competition. As such, the dataset you see in `input/` may differ slightly from what is described in the competition instructions. Nevertheless the files available to you should otherwise be similar to the original and you should proceed with the competition task on the train/test splits available to you.
- **Submission checker**: We provide a tool for checking the validity of your submission file, in the form of a server endpoint at `http://localhost:5001/validate`. If you post a submission file to the server (e.g. `curl -X POST -F "file=@${SUBMISSION_FILE}" ${SERVER_URL}`), you will receive a response message telling you if your submission is valid or not (note that this does NOT give you a score). For your convenience, we provide a script `validate_submission.sh` which can help you make this submission to the validation server.
- **Cheating**: You are not allowed to view others' solutions to this competition. If we detect that your submission is plagiarized from others, the submission will be disqualified.

Your submission will be graded based on the metric in the competition-specific instructions. Your goal is to achieve the best score possible on the competition task.

Wherever there is a conflict between the points above and the competition-specific instructions in `input/description.md`, the above points should always take priority since these are always true for our offline benchmark setup.

ADDITIONAL NOTES
------

- **Compute**: You have access to 1 NVIDIA A100-SXM4-80GB with the appropriate drivers installed.
- **Total Runtime**: You have a maximum of 24hours 0mins 0secs hours to attempt this task. You may iteratively develop your solution within this time frame, but bear in mind that program runtime also counts towards this limit.
- **Total Steps**: You have a maximum of 500 steps to submit your solution.
- You will be informed of the remaining time and steps at each step.
- **Use as much of the available time as possible to refine and optimize your submission**: Your goal is to achieve the best possible score, not just to submit your first working solution. Consider strategies like validating your answer using the "Validate Submission" tool at the http://localhost:5000/validate endpoint, manually spot-checking predictions, building custom validation sets and grading functions, and comparing different algorithms. You may keep working until the time limit expires -- as long as your best submission is stored at the designated location at the end of your run, it will be picked up for grading.

COMPETITION INSTRUCTIONS
------

# RAVIR - Retinal Artery and Vein Segmentation in Infrared Reflectance Imaging

**Challenge Website:** https://ravir.grand-challenge.org/
**Year:** 2022
**Journal:** IEEE Journal of Biomedical and Health Informatics
**Data License:** CC BY-NC-SA 4.0
**Dataset:** https://drive.google.com/file/d/1ZlZoSStvE9VCRq3bJiGhQH931EF0h3hh/view

## Overview

RAVIR is a dataset and challenge for the **semantic segmentation and quantitative analysis of retinal arteries and veins** in infrared reflectance imaging. This challenge enables the creation of deep learning models that distinguish vessel types (arteries vs. veins) without extensive post-processing.

## Background

### Clinical Significance

The retinal vasculature provides crucial diagnostic information for systemic diseases:

1. **Direct Microvasculature Observation**
   - Retina is the **only anatomical site** where microvasculature can be directly observed non-invasively
   - Primary microvascular involvement in systemic conditions
   - Real-time assessment without tissue sampling

2. **Surrogate Biomarker for Systemic Disease**
   - **Hypertension**: Vessel narrowing, arteriovenous nicking
   - **Diabetes**: Microvascular changes, microaneurysms
   - **Cardiovascular disease**: Vessel caliber alterations
   - **Stroke risk**: Retinal vessel morphometry

3. **Clinical Applications**
   - Disease diagnosis and staging
   - Treatment monitoring and response assessment
   - Disease progression tracking
   - Risk stratification

## Task Definition

**Goal:** Automatically segment and classify retinal blood vessels into arteries and veins from infrared reflectance images.

**Input:** Infrared reflectance (IR) retinal images
**Output:** Semantic segmentation mask with three classes:
- **Background**: Label 0
- **Artery**: Label 128
- **Vein**: Label 255

## Dataset Characteristics

### Imaging Modality

**Infrared Scanning Laser Ophthalmoscopy (SLO)**

Advantages over traditional fundus photography:
- **Higher quality and contrast**
- **Less affected by optical media opacities** (cataracts, corneal haze)
- **Pupil size independent**
- **Improved vessel visualization**
- **Better signal-to-noise ratio**

### Technical Specifications

- **Wavelength**: 815 nm (near-infrared)
- **Camera**: Heidelberg Spectralis
- **Field of View**: 30°
- **Image Size**: 768 × 768 pixels
- **Pixel Resolution**: 12.5 microns per pixel
- **Format**: PNG (Portable Network Graphics)
- **Compression**: Lossless

### Dataset Split

- **Training Set**: Multiple cases with ground truth annotations
- **Test Set**: 19 cases (IR_Case_006.png to IR_Case_060.png)
  - **Note**: IR_Case_002.png was removed as duplicate (if downloaded before Aug 16, 2022)

### Annotations

Expert-level manual annotations distinguishing:
- **Arteries**: Typically brighter, narrower, more tortuous
- **Veins**: Typically darker, wider, straighter

## Infrared vs. Traditional Fundus Imaging

### Why Infrared?

Traditional color fundus photography has limitations:
- Affected by media opacities (cataracts)
- Requires good pupil dilation
- Lower contrast in diseased states
- More sensitive to illumination variations

Infrared SLO advantages:
- **Penetrates media opacities** better
- **Works with smaller pupils**
- **Higher vessel-to-background contrast**
- **More consistent across patients**
- **Less affected by pigmentation variations**

## Submission Format

### File Requirements

1. **Image Format**:
   - PNG files as 2D maps with size (768, 768)
   - **NOT** (768, 768, 3) - will trigger evaluation errors

2. **Class Labels**:
   - Background: 0
   - Artery: 128
   - Vein: 255

3. **Filenames**:
   - Must **exactly match** test set names
   - Format: `IR_Case_XXX.png`
   - Range: IR_Case_006 to IR_Case_060
   - Total: 19 files

4. **Submission Structure**:
```
test/
├── IR_Case_006.png
├── IR_Case_007.png
├── IR_Case_008.png
├── ...
└── IR_Case_060.png
```

5. **Submission Package**:
   - Place all predictions in folder named `test`
   - Compress folder to ZIP format
   - Upload to challenge server

## Evaluation Metrics

### Primary Metric

**Mean Dice Score** - Average of artery and vein Dice scores

### All Metrics Computed

For both **Artery** and **Vein** classes separately:

1. **Dice Similarity Coefficient (DSC)**
   ```
   Dice = 2 * |A ∩ B| / (|A| + |B|)
   ```
   - Measures overlap between prediction and ground truth
   - Range: 0 (no overlap) to 1 (perfect overlap)

2. **Jaccard Index (IoU)**
   ```
   Jaccard = |A ∩ B| / |A ∪ B|
   ```
   - Intersection over Union
   - More strict than Dice (penalizes errors more)

### Leaderboard Ranking

Participants ranked by **best average Dice score** across:
- All test images (19 cases)
- Both vessel classes (arteries and veins)

## Technical Challenges

### Artery-Vein Differentiation

Distinguishing arteries from veins requires:
- **Morphological features**: Width, tortuosity, branching patterns
- **Intensity characteristics**: Arteries often brighter in IR
- **Topological relationships**: Crossing patterns, vessel hierarchy
- **Contextual information**: Spatial relationships, vessel networks

### Common Difficulties

1. **Small vessels**: Difficult to classify confidently
2. **Crossing points**: Artery-vein crossings create ambiguity
3. **Pathological changes**: Disease alters normal appearance
4. **Image quality variations**: Different patients, imaging conditions
5. **Vessel continuity**: Maintaining consistent labels along vessel paths

## Clinical Relevance

### Quantitative Vessel Analysis

Automated segmentation enables:

1. **Vessel Caliber Measurement**
   - Artery-to-vein ratio (AVR)
   - Central retinal artery/vein equivalent (CRAE/CRVE)
   - Diagnostic and prognostic biomarkers

2. **Morphometric Features**
   - Tortuosity indices
   - Fractal dimension
   - Branching angles
   - Vessel density

3. **Disease Monitoring**
   - Longitudinal tracking of vessel changes
   - Treatment response assessment
   - Disease progression quantification

### Target Conditions

- Hypertensive retinopathy
- Diabetic retinopathy
- Retinal vein/artery occlusions
- Cardiovascular disease risk
- Stroke prediction

## Important Notes

### Dataset Version

- Datasets downloaded **before August 16, 2022** contain duplicate image `IR_Case_002.png`
- **Must remove** IR_Case_002.png before submission
- Failure to remove causes evaluation errors
- Datasets downloaded **after August 16, 2022** are already corrected

### Institutional Approval

- Project approved by UCLA Institutional Review Board
- Adheres to Declaration of Helsinki tenets
- Patient de-identification performed

## Data Usage Agreement

RAVIR dataset is distributed under **CC BY-NC-SA 4.0 License**:
- **Non-commercial use only**
- Attribution required
- Share-alike (derivatives under same license)

### Required Citations

If using RAVIR dataset, **must cite both**:

**[1] Dataset Paper:**
```
Hatamizadeh, A., Hosseini, H., Patel, N., Choi, J., Pole, C., Hoeferlin, C.,
Schwartz, S. and Terzopoulos, D., 2022. RAVIR: A Dataset and Methodology for
the Semantic Segmentation and Quantitative Analysis of Retinal Arteries and
Veins in Infrared Reflectance Imaging. IEEE Journal of Biomedical and Health
Informatics.
```

**[2] Dissertation:**
```
Hatamizadeh, A., 2020. An Artificial Intelligence Framework for the Automated
Segmentation and Quantitative Analysis of Retinal Vasculature. University of
California, Los Angeles.
```

## Baseline Approaches

### Traditional Methods

- Vessel tracking with intensity profiles
- Graph-based optimization
- Rule-based classification using vessel width

### Deep Learning

- U-Net and variants for segmentation
- Multi-task learning (segmentation + classification)
- Attention mechanisms for artery-vein distinction
- Graph neural networks for vessel topology

## Resources

- **Challenge Website**: https://ravir.grand-challenge.org/
- **Dataset Download**: https://drive.google.com/file/d/1ZlZoSStvE9VCRq3bJiGhQH931EF0h3hh/view
- **Paper**: IEEE Journal of Biomedical and Health Informatics, 2022

## Contact

For questions about the challenge, refer to the official RAVIR Grand Challenge page.
